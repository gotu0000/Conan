{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Circle\n",
    "import seaborn as sns; \n",
    "from IPython.display import HTML\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import r2_score\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config parser\n",
    "import configparser\n",
    "\n",
    "sys.path.insert(0, '../Common/')\n",
    "from AISDataManager import AISDataManager\n",
    "import Constants as c\n",
    "import HMUtils as hMUtil\n",
    "import TimeUtils as timeUtils\n",
    "import GeoCompute as gC\n",
    "\n",
    "#MyConfig.INI stores all the run time constants\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../MyConfig.INI')\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "aISDM = AISDataManager()\n",
    "numCores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonMin = (float)(config['SEC_ORDER_VISUAL']['LON_MIN'])\n",
    "lonMax = (float)(config['SEC_ORDER_VISUAL']['LON_MAX'])\n",
    "\n",
    "latMin = (float)(config['SEC_ORDER_VISUAL']['LAT_MIN'])\n",
    "latMax = (float)(config['SEC_ORDER_VISUAL']['LAT_MAX'])\n",
    "\n",
    "print(lonMin,latMin)\n",
    "print(lonMax,latMax)\n",
    "\n",
    "increStep = (float)(config['SEC_ORDER_VISUAL']['INCR_STEP'])\n",
    "incrRes = (int)(config['SEC_ORDER_VISUAL']['INCR_RES'])\n",
    "\n",
    "boundary = (float)(config['SEC_ORDER_VISUAL']['BOUNDARY'])\n",
    "\n",
    "fileDir = config['TP_SEC_ORDER']['SOURCE_DIR']\n",
    "dirToStore = config['TP_SEC_ORDER']['DEST_DIR']\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj1/\"\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj2/\"\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj3/\"\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj4/\"\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj5/\"\n",
    "# destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj6/\"\n",
    "destDirTraj = \"../Data/M120_50_M119_00_33_90_34_44/Display/Traj7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is useful for mapping\n",
    "#probabilistic location\n",
    "heatMapGrid = hMUtil.generate_grid(lonMin, lonMax, latMin, latMax, increStep, incrRes)\n",
    "boundaryArray = heatMapGrid[2]\n",
    "horizontalAxis = heatMapGrid[0]\n",
    "verticalAxis = heatMapGrid[1]\n",
    "totalStates = horizontalAxis.shape[0] * verticalAxis.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonCen = (lonMin + lonMax)/2\n",
    "latCen = (latMin + latMax)/2\n",
    "print(lonCen)\n",
    "print(latCen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate trajectory list\n",
    "#for one vessel\n",
    "MMSI_DIR = \"../Data/M120_50_M119_00_33_90_34_44/MMSI/\"\n",
    "def get_vessel_data(vesselName):\n",
    "    oneVessel = MMSI_DIR + vesselName +\"_Sorted.csv\"\n",
    "    oneVesselData,_ = aISDM.load_data_from_csv(oneVessel)\n",
    "    return oneVesselData\n",
    "\n",
    "def get_vessel_lon_lat_from_traj(vesselName):\n",
    "    oneVesselData = get_vessel_data(vesselName)\n",
    "    print(oneVesselData.shape)\n",
    "    oneVesselLon = oneVesselData['LON']\n",
    "    oneVesselLat = oneVesselData['LAT']\n",
    "    return oneVesselLon, oneVesselLat\n",
    "\n",
    "    \n",
    "oneVesselData = get_vessel_data(\"565819000\")\n",
    "oneVesselLon,oneVesselLat = get_vessel_lon_lat_from_traj(\"565819000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneVesselTime = oneVesselData['DateTime']\n",
    "for i in range(oneVesselLon.shape[0]):\n",
    "    print(i,oneVesselTime[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for trajectory 1 and 2\n",
    "# timeIntervalList = \"../Data/TimeInterval/HalfHourIntvl1704To1705_00.txt\"\n",
    "# timeIntervalList1 = \"../Data/TimeInterval/HalfHourIntvl1704To1705_05.txt\"\n",
    "# timeIntervalList2 = \"../Data/TimeInterval/HalfHourIntvl1704To1705_10.txt\"\n",
    "# timeIntervalList3 = \"../Data/TimeInterval/HalfHourIntvl1704To1705_15.txt\"\n",
    "# timeIntervalList4 = \"../Data/TimeInterval/HalfHourIntvl1704To1705_20.txt\"\n",
    "# timeIntervalList5 = \"../Data/TimeInterval/HalfHourIntvl1704To1705_25.txt\"\n",
    "\n",
    "#for trajectory 3\n",
    "\n",
    "# timeIntervalList = \"../Data/TimeInterval/HalfHourIntvl1706To1707_00.txt\"\n",
    "# timeIntervalList1 = \"../Data/TimeInterval/HalfHourIntvl1706To1707_05.txt\"\n",
    "# timeIntervalList2 = \"../Data/TimeInterval/HalfHourIntvl1706To1707_10.txt\"\n",
    "# timeIntervalList3 = \"../Data/TimeInterval/HalfHourIntvl1706To1707_15.txt\"\n",
    "# timeIntervalList4 = \"../Data/TimeInterval/HalfHourIntvl1706To1707_20.txt\"\n",
    "# timeIntervalList5 = \"../Data/TimeInterval/HalfHourIntvl1706To1707_25.txt\"\n",
    "\n",
    "#for trajectory 4 and 5\n",
    "# timeIntervalList = \"../Data/TimeInterval/HalfHourIntvl1707To1708_00.txt\"\n",
    "# timeIntervalList1 = \"../Data/TimeInterval/HalfHourIntvl1707To1708_05.txt\"\n",
    "# timeIntervalList2 = \"../Data/TimeInterval/HalfHourIntvl1707To1708_10.txt\"\n",
    "# timeIntervalList3 = \"../Data/TimeInterval/HalfHourIntvl1707To1708_15.txt\"\n",
    "# timeIntervalList4 = \"../Data/TimeInterval/HalfHourIntvl1707To1708_20.txt\"\n",
    "# timeIntervalList5 = \"../Data/TimeInterval/HalfHourIntvl1707To1708_25.txt\"\n",
    "\n",
    "#for trajectory 6\n",
    "timeIntervalList = \"../Data/TimeInterval/HalfHourIntvl1708To1709_00.txt\"\n",
    "timeIntervalList1 = \"../Data/TimeInterval/HalfHourIntvl1708To1709_05.txt\"\n",
    "timeIntervalList2 = \"../Data/TimeInterval/HalfHourIntvl1708To1709_10.txt\"\n",
    "timeIntervalList3 = \"../Data/TimeInterval/HalfHourIntvl1708To1709_15.txt\"\n",
    "timeIntervalList4 = \"../Data/TimeInterval/HalfHourIntvl1708To1709_20.txt\"\n",
    "timeIntervalList5 = \"../Data/TimeInterval/HalfHourIntvl1708To1709_25.txt\"\n",
    "\n",
    "timeWindows = [line.rstrip('\\n') for line in open(timeIntervalList)]\n",
    "timeWindows1 = [line.rstrip('\\n') for line in open(timeIntervalList1)]\n",
    "timeWindows2 = [line.rstrip('\\n') for line in open(timeIntervalList2)]\n",
    "timeWindows3 = [line.rstrip('\\n') for line in open(timeIntervalList3)]\n",
    "timeWindows4 = [line.rstrip('\\n') for line in open(timeIntervalList4)]\n",
    "timeWindows5 = [line.rstrip('\\n') for line in open(timeIntervalList5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the last instance of the position data \n",
    "#for one of the vessel\n",
    "#and that can be used for the prediction\n",
    "oneVesselLastData = pd.DataFrame()\n",
    "oneVesselLastData1 = pd.DataFrame()\n",
    "oneVesselLastData2 = pd.DataFrame()\n",
    "oneVesselLastData3 = pd.DataFrame()\n",
    "oneVesselLastData4 = pd.DataFrame()\n",
    "oneVesselLastData5 = pd.DataFrame()\n",
    "#based on time stamps \n",
    "for timeSlot in timeWindows:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData = oneVesselLastData.append(invertedTimelyDF, ignore_index = True)\n",
    "    \n",
    "for timeSlot in timeWindows1:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData1 = oneVesselLastData1.append(invertedTimelyDF, ignore_index = True)\n",
    "    \n",
    "for timeSlot in timeWindows2:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData2 = oneVesselLastData2.append(invertedTimelyDF, ignore_index = True)\n",
    "    \n",
    "for timeSlot in timeWindows3:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData3 = oneVesselLastData3.append(invertedTimelyDF, ignore_index = True)\n",
    "    \n",
    "for timeSlot in timeWindows4:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData4 = oneVesselLastData4.append(invertedTimelyDF, ignore_index = True)\n",
    "    \n",
    "for timeSlot in timeWindows5:\n",
    "    temp = timeSlot.split(',')\n",
    "    startTime = temp[0]\n",
    "    endTime = temp[1]\n",
    "\n",
    "    timelyDF = aISDM.filter_based_on_time_stamp(oneVesselData,'DateTime',startTime,endTime)\n",
    "    oneVesselRows = timelyDF.shape[0]\n",
    "    \n",
    "    invertedTimelyDF = aISDM.inver_df(timelyDF)\n",
    "    invertedTimelyDF = invertedTimelyDF.drop_duplicates(subset=\"MMSI\")\n",
    "    \n",
    "    oneVesselLastData5 = oneVesselLastData5.append(invertedTimelyDF, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"**************0\")\n",
    "print(oneVesselLastData)\n",
    "print(\"**************1\")\n",
    "print(oneVesselLastData1)\n",
    "print(\"**************2\")\n",
    "print(oneVesselLastData2)\n",
    "print(\"**************3\")\n",
    "print(oneVesselLastData3)\n",
    "print(\"**************4\")\n",
    "print(oneVesselLastData4)\n",
    "print(\"**************5\")\n",
    "print(oneVesselLastData5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for traj1\n",
    "# oneVesselLastDataOne = oneVesselLastData.iloc[0:15,:]\n",
    "# oneVesselLastDataOne1 = oneVesselLastData1.iloc[0:15,:]\n",
    "# oneVesselLastDataOne2 = oneVesselLastData2.iloc[0:16,:]\n",
    "# oneVesselLastDataOne3 = oneVesselLastData3.iloc[0:16,:]\n",
    "# oneVesselLastDataOne4 = oneVesselLastData4.iloc[0:16,:]\n",
    "# oneVesselLastDataOne5 = oneVesselLastData5.iloc[0:16,:]\n",
    "\n",
    "#for traj2\n",
    "# oneVesselLastDataOne = oneVesselLastData.iloc[15:,:]\n",
    "# oneVesselLastDataOne1 = oneVesselLastData1.iloc[15:,:]\n",
    "# oneVesselLastDataOne2 = oneVesselLastData2.iloc[16:,:]\n",
    "# oneVesselLastDataOne3 = oneVesselLastData3.iloc[16:,:]\n",
    "# oneVesselLastDataOne4 = oneVesselLastData4.iloc[16:,:]\n",
    "# oneVesselLastDataOne5 = oneVesselLastData5.iloc[16:,:]\n",
    "\n",
    "#for traj3\n",
    "# oneVesselLastDataOne = oneVesselLastData.iloc[1:,:]\n",
    "# oneVesselLastDataOne1 = oneVesselLastData1.iloc[1:,:]\n",
    "# oneVesselLastDataOne2 = oneVesselLastData2.iloc[1:,:]\n",
    "# oneVesselLastDataOne3 = oneVesselLastData3.iloc[1:,:]\n",
    "# oneVesselLastDataOne4 = oneVesselLastData4.iloc[1:,:]\n",
    "# oneVesselLastDataOne5 = oneVesselLastData5.iloc[1:,:]\n",
    "\n",
    "#for traj4\n",
    "# oneVesselLastDataOne = oneVesselLastData.iloc[1:11,:]\n",
    "# oneVesselLastDataOne1 = oneVesselLastData1.iloc[1:10,:]\n",
    "# oneVesselLastDataOne2 = oneVesselLastData2.iloc[1:10,:]\n",
    "# oneVesselLastDataOne3 = oneVesselLastData3.iloc[1:11,:]\n",
    "# oneVesselLastDataOne4 = oneVesselLastData4.iloc[1:11,:]\n",
    "# oneVesselLastDataOne5 = oneVesselLastData5.iloc[1:11,:]\n",
    "\n",
    "#for traj5\n",
    "# oneVesselLastDataOne = oneVesselLastData.iloc[13:,:]\n",
    "# oneVesselLastDataOne1 = oneVesselLastData1.iloc[12:,:]\n",
    "# oneVesselLastDataOne2 = oneVesselLastData2.iloc[12:,:]\n",
    "# oneVesselLastDataOne3 = oneVesselLastData3.iloc[13:,:]\n",
    "# oneVesselLastDataOne4 = oneVesselLastData4.iloc[13:,:]\n",
    "# oneVesselLastDataOne5 = oneVesselLastData5.iloc[13:,:]\n",
    "\n",
    "#for traj6\n",
    "oneVesselLastDataOne = oneVesselLastData.iloc[5:,:]\n",
    "oneVesselLastDataOne1 = oneVesselLastData1.iloc[5:,:]\n",
    "oneVesselLastDataOne2 = oneVesselLastData2.iloc[5:,:]\n",
    "oneVesselLastDataOne3 = oneVesselLastData3.iloc[5:,:]\n",
    "oneVesselLastDataOne4 = oneVesselLastData4.iloc[5:,:]\n",
    "oneVesselLastDataOne5 = oneVesselLastData5.iloc[5:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*************0\")\n",
    "print(oneVesselLastDataOne)\n",
    "print(\"*************1\")\n",
    "print(oneVesselLastDataOne1)\n",
    "print(\"*************2\")\n",
    "print(oneVesselLastDataOne2)\n",
    "print(\"*************3\")\n",
    "print(oneVesselLastDataOne3)\n",
    "print(\"*************4\")\n",
    "print(oneVesselLastDataOne4)\n",
    "print(\"*************5\")\n",
    "print(oneVesselLastDataOne5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj = []\n",
    "#for traj 1\n",
    "# traj.append(oneVesselLastDataOne2)\n",
    "# traj.append(oneVesselLastDataOne3)\n",
    "# traj.append(oneVesselLastDataOne4)\n",
    "# traj.append(oneVesselLastDataOne5)\n",
    "# traj.append(oneVesselLastDataOne)\n",
    "# traj.append(oneVesselLastDataOne1)\n",
    "\n",
    "#for traj 2\n",
    "# traj.append(oneVesselLastDataOne3)\n",
    "# traj.append(oneVesselLastDataOne4)\n",
    "# traj.append(oneVesselLastDataOne5)\n",
    "# traj.append(oneVesselLastDataOne)\n",
    "# traj.append(oneVesselLastDataOne1)\n",
    "# traj.append(oneVesselLastDataOne2)\n",
    "\n",
    "#for traj 3\n",
    "# traj.append(oneVesselLastDataOne3)\n",
    "# traj.append(oneVesselLastDataOne4)\n",
    "# traj.append(oneVesselLastDataOne5)\n",
    "# traj.append(oneVesselLastDataOne)\n",
    "# traj.append(oneVesselLastDataOne1)\n",
    "# traj.append(oneVesselLastDataOne2)\n",
    "\n",
    "#for traj 4\n",
    "# traj.append(oneVesselLastDataOne3)\n",
    "# traj.append(oneVesselLastDataOne4)\n",
    "# traj.append(oneVesselLastDataOne5)\n",
    "# traj.append(oneVesselLastDataOne)\n",
    "# traj.append(oneVesselLastDataOne1)\n",
    "# traj.append(oneVesselLastDataOne2)\n",
    "\n",
    "#for traj 5\n",
    "# traj.append(oneVesselLastDataOne)\n",
    "# traj.append(oneVesselLastDataOne1)\n",
    "# traj.append(oneVesselLastDataOne2)\n",
    "# traj.append(oneVesselLastDataOne3)\n",
    "# traj.append(oneVesselLastDataOne4)\n",
    "# traj.append(oneVesselLastDataOne5)\n",
    "\n",
    "#for traj 6\n",
    "traj.append(oneVesselLastDataOne2)\n",
    "traj.append(oneVesselLastDataOne3)\n",
    "traj.append(oneVesselLastDataOne4)\n",
    "traj.append(oneVesselLastDataOne5)\n",
    "traj.append(oneVesselLastDataOne)\n",
    "traj.append(oneVesselLastDataOne1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the maximum number of rows\n",
    "maxRows = max(oneVesselLastDataOne.shape[0] \\\n",
    "              , oneVesselLastDataOne1.shape[0] \\\n",
    "              , oneVesselLastDataOne2.shape[0] \\\n",
    "              , oneVesselLastDataOne3.shape[0] \\\n",
    "              , oneVesselLastDataOne4.shape[0] \\\n",
    "              , oneVesselLastDataOne5.shape[0] \\\n",
    "             )\n",
    "\n",
    "print(maxRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolatedTraj = pd.DataFrame()\n",
    "for i in range(maxRows):\n",
    "    if(i < traj[0].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[0].iloc[i,:], ignore_index = True)\n",
    "    if(i < traj[1].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[1].iloc[i,:], ignore_index = True)\n",
    "    if(i < traj[2].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[2].iloc[i,:], ignore_index = True)\n",
    "    if(i < traj[3].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[3].iloc[i,:], ignore_index = True)\n",
    "    if(i < traj[4].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[4].iloc[i,:], ignore_index = True)\n",
    "    if(i < traj[5].shape[0]):\n",
    "        interpolatedTraj = interpolatedTraj.append(traj[5].iloc[i,:], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(interpolatedTraj.shape[0]):\n",
    "    print(interpolatedTraj.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opFile = dirToStore + 'TPM.npz'\n",
    "# opFile = dirToStore + 'TPM_.npz'\n",
    "tpMatrix = scipy.sparse.load_npz(opFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tpMatrix.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vessel_init_status(lonStart,latStart):\n",
    "    vesselState = np.zeros((horizontalAxis.shape[0]*verticalAxis.shape[0]))\n",
    "    for boundary in boundaryArray :\n",
    "        if((lonStart >= boundary[0]) \\\n",
    "            and (lonStart < boundary[1]) \\\n",
    "           \n",
    "            and (latStart >= boundary[2]) \\\n",
    "            and (latStart < boundary[3]) \\\n",
    "          ):\n",
    "            vesselState[boundary[4]] = 1.0\n",
    "            break\n",
    "    return vesselState\n",
    "\n",
    "#takes inital state vector\n",
    "#and number of steps \n",
    "#uses transition probabilities to generate the path\n",
    "def generate_path(vesselStatus):\n",
    "    return (vesselStatus.T @ tpMatrix).flatten()\n",
    "\n",
    "def generate_vessel_prev_cur_status(prevState,currState):\n",
    "    vesselState = np.zeros((totalStates*totalStates))\n",
    "    stateCounter = 0\n",
    "    for i in range(prevState.shape[0]):\n",
    "        for j in range(currState.shape[0]):\n",
    "            vesselState[stateCounter] = prevState[i]*currState[j]\n",
    "            stateCounter = stateCounter + 1\n",
    "    return vesselState\n",
    "\n",
    "def generate_vessel_prev_cur_status_(prevState,currState):\n",
    "    vesselState = np.zeros((prevState.shape[0]*currState.shape[0]))\n",
    "    stateCounter = 0\n",
    "    for i in range(prevState.shape[0]):\n",
    "        for j in range(currState.shape[0]):\n",
    "            vesselState[stateCounter] = prevState[i]*currState[j]\n",
    "            stateCounter = stateCounter + 1\n",
    "    return vesselState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rowSum = np.sum(tpMatrix, axis=1)\n",
    "rowSumZeroIdx = np.argwhere(rowSum == 0)\n",
    "rowSumZeroIdx = rowSumZeroIdx.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takesdata frame\n",
    "#extracts lon and lat\n",
    "#returns prediction list\n",
    "def generate_prediction_list(dFObj):\n",
    "    oneVesselLastDataOneLon = dFObj[\"LON\"]\n",
    "    oneVesselLastDataOneLat = dFObj[\"LAT\"]\n",
    "    \n",
    "    onePredict = []\n",
    "    vesselPrevState = get_vessel_init_status(oneVesselLastDataOneLon.iloc[0],oneVesselLastDataOneLat.iloc[0])\n",
    "    onePredict.append(vesselPrevState.copy())\n",
    "    vesselCurrState = get_vessel_init_status(oneVesselLastDataOneLon.iloc[1],oneVesselLastDataOneLat.iloc[1])\n",
    "    onePredict.append(vesselCurrState.copy())\n",
    "    vesselState = generate_vessel_prev_cur_status(vesselPrevState,vesselCurrState)\n",
    "    for i in range(dFObj.shape[0]-2):\n",
    "        vesselProbState = generate_path(vesselState)\n",
    "        print(i)\n",
    "        print(np.sum(vesselProbState))\n",
    "        onePredict.append(vesselProbState.copy())\n",
    "        vesselPrevState = vesselCurrState.copy()\n",
    "        vesselCurrState = vesselProbState.copy()\n",
    "        vesselState = generate_vessel_prev_cur_status(vesselPrevState,vesselCurrState)\n",
    "        #make probabilities zero\n",
    "        vesselState[rowSumZeroIdx] = 0\n",
    "        vesselState = vesselState/np.sum(vesselState)\n",
    "        print(np.sum(vesselState))\n",
    "    return onePredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onePredict0 = generate_prediction_list(traj[0])\n",
    "onePredict1 = generate_prediction_list(traj[1])\n",
    "onePredict2 = generate_prediction_list(traj[2])\n",
    "onePredict3 = generate_prediction_list(traj[3])\n",
    "onePredict4 = generate_prediction_list(traj[4])\n",
    "onePredict5 = generate_prediction_list(traj[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolatedProbTraj = []\n",
    "for i in range(maxRows):\n",
    "    if(i < len(onePredict0)):\n",
    "        interpolatedProbTraj.append(onePredict0[i])\n",
    "    if(i < len(onePredict1)):\n",
    "        interpolatedProbTraj.append(onePredict1[i])\n",
    "    if(i < len(onePredict2)):\n",
    "        interpolatedProbTraj.append(onePredict2[i])\n",
    "    if(i < len(onePredict3)):\n",
    "        interpolatedProbTraj.append(onePredict3[i])\n",
    "    if(i < len(onePredict4)):\n",
    "        interpolatedProbTraj.append(onePredict4[i])\n",
    "    if(i < len(onePredict5)):\n",
    "        interpolatedProbTraj.append(onePredict5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(onePredict0))\n",
    "print(len(onePredict1))\n",
    "print(len(onePredict2))\n",
    "print(len(onePredict3))\n",
    "print(len(onePredict4))\n",
    "print(len(onePredict5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interpolatedProbTraj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(interpolatedProbTraj)):\n",
    "    opFile = destDirTraj + str(i) +'.npy'\n",
    "    np.save(opFile, interpolatedProbTraj[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(interpolatedTraj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aISDM.save_data_to_csv(interpolatedTraj,(destDirTraj+\"True.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
