{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from matplotlib.patches import Circle\n",
    "import seaborn as sns; \n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config parser\n",
    "import configparser\n",
    "\n",
    "sys.path.insert(0, '../Common/')\n",
    "from AISDataManager import AISDataManager\n",
    "import Constants as c\n",
    "import HMUtils as hMUtil\n",
    "import TimeUtils as timeUtils\n",
    "import GeoCompute as gC\n",
    "\n",
    "#MyConfig.INI stores all the run time constants\n",
    "config = configparser.ConfigParser()\n",
    "config.read('../MyConfig.INI')\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "aISDM = AISDataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonMin = (float)(config['TRAJ_PRED_LSTM']['LON_MIN'])\n",
    "lonMax = (float)(config['TRAJ_PRED_LSTM']['LON_MAX'])\n",
    "\n",
    "latMin = (float)(config['TRAJ_PRED_LSTM']['LAT_MIN'])\n",
    "latMax = (float)(config['TRAJ_PRED_LSTM']['LAT_MAX'])\n",
    "\n",
    "print(lonMin,latMin)\n",
    "print(lonMax,latMax)\n",
    "\n",
    "increStep = (float)(config['TRAJ_PRED_LSTM']['INCR_STEP'])\n",
    "incrRes = (int)(config['TRAJ_PRED_LSTM']['INCR_RES'])\n",
    "\n",
    "sourceDir = config['TRAJ_PRED_LSTM']['SOURCE_DIR']\n",
    "print(sourceDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatMapGrid = hMUtil.generate_grid(lonMin, lonMax, latMin, latMax, increStep, incrRes)\n",
    "boundaryArray = heatMapGrid[2]\n",
    "horizontalAxis = heatMapGrid[0]\n",
    "verticalAxis = heatMapGrid[1]\n",
    "totalStates = horizontalAxis.shape[0] * verticalAxis.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first read the data frame\n",
    "#convert LON and LAT into cooresponding \n",
    "# def get_index_from_lon_lat(lat,lon):\n",
    "def get_index_from_lon_lat(latLonRow):\n",
    "    retVal = -1\n",
    "    lat = latLonRow['LAT']\n",
    "    lon = latLonRow['LON']\n",
    "    for boundary in boundaryArray: \n",
    "        if(lon >= boundary[0]) and (lon < boundary[1]) \\\n",
    "            and (lat >= boundary[2]) and (lat < boundary[3]):\n",
    "            retVal = boundary[4]\n",
    "            break \n",
    "    return retVal\n",
    "\n",
    "#will convert dataframe into sequence of numbers\n",
    "#which can be used to make data for LSTM\n",
    "def convert_traj_df_to_state_sequence(num):\n",
    "    #read the dataframe\n",
    "    sorceFile = sourceDir + str(num) + '.csv'\n",
    "    sourceDF,_ = aISDM.load_data_from_csv(sorceFile)\n",
    "    #conver every LON and LAT to sequence of numbers\n",
    "    ret = sourceDF.apply(get_index_from_lon_lat,axis=1)\n",
    "    return ret.to_numpy()\n",
    "    \n",
    "# convert_traj_df_to_state_sequence(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of all such trajectories\n",
    "#number goes from 0 to 80000\n",
    "#that much is going to be our training data\n",
    "trajSeqList = []\n",
    "\n",
    "#FIXME get number from Config file\n",
    "for trajNum in range(0,60802):\n",
    "    trajSeqList.append(convert_traj_df_to_state_sequence(trajNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lessDataCount = 0;\n",
    "for trajNum in range(0,60802):\n",
    "    if(len(trajSeqList[trajNum]) <= 2):\n",
    "        lessDataCount = lessDataCount + 1\n",
    "        \n",
    "print(lessDataCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes numpy array and returns x and y for\n",
    "#time series prediction\n",
    "def convert_seq_to_x_y(seq):\n",
    "    #first column\n",
    "    #-2 is is to take care of boundary condition\n",
    "    #since we are considering 2 time stamps for the input data\n",
    "    firstCol = seq[:-2].copy()\n",
    "    firstCol = np.reshape(firstCol,(firstCol.shape[0],1))\n",
    "#     print(firstCol)\n",
    "#     print(firstCol.shape)\n",
    "    #second column shifted by 1 time instances\n",
    "    secCol = seq[1:-1].copy()\n",
    "    secCol = np.reshape(secCol,(secCol.shape[0],1))\n",
    "#     print(secCol)\n",
    "#     print(secCol.shape)\n",
    "    #output is shifted by two time instances\n",
    "    outputLabel = seq[2:].copy()\n",
    "    outputLabel = np.reshape(outputLabel,(outputLabel.shape[0],1))\n",
    "#     print(outputLabel)\n",
    "#     print(outputLabel.shape)\n",
    "    xData = np.hstack((firstCol,secCol))\n",
    "#     print(xData.shape)\n",
    "    return xData, outputLabel\n",
    "    \n",
    "# convert_seq_to_x_y(trajSeqList[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now iterate throgh trajSeqList \n",
    "#and keep on stacking them vertically\n",
    "#to make giant input and output matrix\n",
    "xData = np.zeros((0,2))\n",
    "yData = np.zeros((0,1))\n",
    "print(xData.shape)\n",
    "print(yData.shape)\n",
    "for trajNum in range(len(trajSeqList)):\n",
    "    if(len(trajSeqList[trajNum]) > 2):\n",
    "        xTemp,yTemp = convert_seq_to_x_y(trajSeqList[trajNum])\n",
    "        xData = np.vstack((xData,xTemp.copy()))\n",
    "        yData = np.vstack((yData,yTemp.copy()))\n",
    "print(xData)\n",
    "print(yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xData.shape)\n",
    "print(yData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xToStore = \"../Data/M120_50_M119_00_33_90_34_44/1004/LSTMData_17/XData.npy\"\n",
    "yToStore = \"../Data/M120_50_M119_00_33_90_34_44/1004/LSTMData_17/YData.npy\"\n",
    "np.save(xToStore, xData)\n",
    "np.save(yToStore, yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xData = np.load(\"../Data/M120_50_M119_00_33_90_34_44/1004/LSTMData_17/XData.npy\")\n",
    "yData = np.load(\"../Data/M120_50_M119_00_33_90_34_44/1004/LSTMData_17/YData.npy\")\n",
    "yData = yData.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xData.shape)\n",
    "print(yData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lon_lat_from_idx(idx):\n",
    "    lonMid, latMid = hMUtil.compute_mid_point(boundaryArray[idx][0] \\\n",
    "                                                            ,boundaryArray[idx][1]\\\n",
    "                                                            ,boundaryArray[idx][2]\\\n",
    "                                                            ,boundaryArray[idx][3]\\\n",
    "                                                            )\n",
    "    return lonMid, latMid\n",
    "\n",
    "def convert_state_to_lon_lat(sampleData):\n",
    "    #previous state\n",
    "    lonPrev, latPrev = get_lon_lat_from_idx((int)(sampleData[0]))\n",
    "    #current state\n",
    "    lonCurr, latCurr = get_lon_lat_from_idx((int)(sampleData[1]))\n",
    "    return np.array([lonPrev, latPrev, lonCurr, latCurr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#like vectorised operation\n",
    "#compute the new xData\n",
    "xLonLatData = np.apply_along_axis(convert_state_to_lon_lat,1,xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalise the data\n",
    "xLonLatData_0 = (xLonLatData[:,0] - lonMin)/(lonMax - lonMin)\n",
    "xLonLatData_0 = np.reshape(xLonLatData_0,(xLonLatData_0.shape[0],1))\n",
    "xLonLatData_1 = (xLonLatData[:,1] - latMin)/(latMax - latMin)\n",
    "xLonLatData_1 = np.reshape(xLonLatData_1,(xLonLatData_1.shape[0],1))\n",
    "xLonLatData_2 = (xLonLatData[:,2] - lonMin)/(lonMax - lonMin)\n",
    "xLonLatData_2 = np.reshape(xLonLatData_2,(xLonLatData_2.shape[0],1))\n",
    "xLonLatData_3 = (xLonLatData[:,3] - latMin)/(latMax - latMin)\n",
    "xLonLatData_3 = np.reshape(xLonLatData_3,(xLonLatData_3.shape[0],1))\n",
    "xLonLatDataNorm = np.hstack((xLonLatData_0,xLonLatData_1,xLonLatData_2,xLonLatData_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xLonLatDataNorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#generator for LON and LAT\n",
    "class DataGeneratorLonLat(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self):\n",
    "        'Initialization'\n",
    "        self.sampleIDX = 0\n",
    "        self.on_epoch_end()\n",
    "        self.batchSize = 32\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return (1900)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        batchFeatures = xLonLatDataNorm[self.sampleIDX:(self.sampleIDX+self.batchSize),:].copy()\n",
    "        batchFeatures = np.reshape(batchFeatures,(self.batchSize, 2, 2))\n",
    "        batchLabels = to_categorical(yData[self.sampleIDX:(self.sampleIDX+self.batchSize),:].copy(),num_classes = totalStates)\n",
    "        self.sampleIDX = self.sampleIDX + 32\n",
    "        return batchFeatures, batchLabels\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        print(\"Epoch End\")\n",
    "        self.sampleIDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences= True, input_shape=(2,2)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=totalStates, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGeneratorLonLat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(training_generator, epochs=500, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"../Data/M120_50_M119_00_33_90_34_44/1004/Models_17/Model_2000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"../Data/M120_50_M119_00_33_90_34_44/1004/Models_17/Model_2000.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleID  = 60\n",
    "#lets try to predict some values\n",
    "print(xData[sampleID])\n",
    "print(yData[sampleID])\n",
    "print(xLonLatDataNorm[sampleID])\n",
    "\n",
    "xTestModel = xLonLatDataNorm[sampleID].copy()\n",
    "xTestModel = np.reshape(xTestModel,(1,2,2))\n",
    "\n",
    "yHatProb = model.predict(xTestModel)\n",
    "print(yHatProb.shape)\n",
    "yHatProb = yHatProb.T\n",
    "yHatProb = yHatProb.flatten()\n",
    "print(yHatProb.shape)\n",
    "maxLoc = yHatProb.argsort()[-3:][::-1]\n",
    "print(maxLoc)\n",
    "print(boundaryArray[maxLoc[0]])\n",
    "print(boundaryArray[2672])\n",
    "print(yHatProb[maxLoc[0]])\n",
    "print(yHatProb[maxLoc[1]])\n",
    "print(yHatProb[maxLoc[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(yHatProb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will take four arguments\n",
    "#[[lonPrev, latPrev, lonCurr, latCurr]] shape is 1x4 or nx4\n",
    "#can be vectorised also\n",
    "def normalize_lon_lat(arr):\n",
    "    #subtract the minimum \n",
    "    #and divide by range\n",
    "    ret02 = (arr[:,[0,2]] - lonMin)/(lonMax - lonMin)\n",
    "    ret13 = (arr[:,[1,3]] - latMin)/(latMax - latMin)\n",
    "    ret0213 = np.hstack((ret02, ret13))\n",
    "    ret0213[:,[0,1,2,3]] = ret0213[:,[0,2,1,3]]\n",
    "    return ret0213\n",
    "\n",
    "\n",
    "def test_normalize_lon_lat():\n",
    "    dummyArr = np.array([-119.27, 34.03, -119.26, 34.04])\n",
    "    print(dummyArr.shape)\n",
    "    print(dummyArr)\n",
    "    dummyArr = np.reshape(dummyArr , (dummyArr.shape[0],1))\n",
    "    print(dummyArr.shape)\n",
    "    print(dummyArr)\n",
    "    dummyArr = dummyArr.T\n",
    "    print(dummyArr.shape)\n",
    "    print(dummyArr)\n",
    "    print(normalize_lon_lat(dummyArr))\n",
    "    \n",
    "normalize_lon_lat(np.array([[-119.27, 34.03, -119.26, 34.04] \\\n",
    "                            ,[-119.26, 34.04, -119.27, 34.03]]))\n",
    "test_normalize_lon_lat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function computes top1 and top3 error \n",
    "#for 30 minutes prediction\n",
    "#takes 3 consecutive trajectory states\n",
    "#prev current and next \n",
    "#in list formate or flatten numpy array\n",
    "#[prev, current, next]\n",
    "def compute_30_min_error(trajState):\n",
    "    #convert the first data to lon and lat\n",
    "    initalTraj = convert_state_to_lon_lat(np.array([trajState[0],trajState[1]]))\n",
    "#     print(trajState[0])\n",
    "#     print(trajState[1])\n",
    "    #now use it to predict the model\n",
    "    #for 30 minutes prediction\n",
    "#     print(initalTraj)\n",
    "#     print(len(initalTraj.shape))\n",
    "    #check for the shape\n",
    "    #to put into sample x feature formate\n",
    "#     print(initalTraj)\n",
    "    if(len(initalTraj.shape) < 2):\n",
    "        initalTraj = np.reshape(initalTraj , (1,initalTraj.shape[0]))\n",
    "\n",
    "    mSample = initalTraj.shape[0]\n",
    "\n",
    "    #first normalise the data\n",
    "    initalTrajNorm = normalize_lon_lat(initalTraj)\n",
    "#     print(initalTrajNorm)\n",
    "    #use the normalised to predict\n",
    "    #reshape input as samples x features x timestamps\n",
    "    initalTrajNorm = np.reshape(initalTrajNorm,(mSample,2,2))\n",
    "#     print(initalTrajNorm)\n",
    "    pred30 = model.predict(initalTrajNorm)\n",
    "    #Lets take top 3\n",
    "    pred30Top3 = pred30.argsort()[-3:][::-1]\n",
    "#     print(pred30Top3.shape)\n",
    "    #now compute distance with top31,top32 and top33\n",
    "    top31 = pred30Top3[0,0]\n",
    "    top32 = pred30Top3[0,1]\n",
    "    top33 = pred30Top3[0,2]\n",
    "#     print(top31)\n",
    "#     print(top32)\n",
    "#     print(top33)\n",
    "    top31LonLat = get_lon_lat_from_idx(top31)\n",
    "    top32LonLat =  get_lon_lat_from_idx(top32)\n",
    "    top33LonLat =  get_lon_lat_from_idx(top33)\n",
    "    #get LON and LAT for true label\n",
    "    trueLonLat = get_lon_lat_from_idx(trajState[2])\n",
    "#     print(trueLonLat)\n",
    "#     print(top31LonLat)\n",
    "#     print(top32LonLat)\n",
    "#     print(top33LonLat)\n",
    "    \n",
    "    top31Err = gC.compute_distance(trueLonLat[0], trueLonLat[1] \\\n",
    "                                      ,top31LonLat[0], top31LonLat[1])\n",
    "\n",
    "    top32Err = gC.compute_distance(trueLonLat[0], trueLonLat[1] \\\n",
    "                                      ,top32LonLat[0], top32LonLat[1])\n",
    "\n",
    "    top33Err = gC.compute_distance(trueLonLat[0], trueLonLat[1] \\\n",
    "                                      ,top33LonLat[0], top33LonLat[1])\n",
    "\n",
    "    print(top31Err, top32Err, top33Err)\n",
    "    return top31Err, min(top31Err, top32Err, top33Err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1Err30Min = []\n",
    "top3Err30Min = []\n",
    "for tarj in range(60802):\n",
    "    trajState = convert_traj_df_to_state_sequence(tarj)\n",
    "    if(len(trajState) > 2):\n",
    "        tempTop1Err, tempTop3Err = compute_30_min_error(trajState)\n",
    "        top1Err30Min.append(tempTop1Err)\n",
    "        top3Err30Min.append(tempTop3Err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(top1Err30Min))\n",
    "print(len(top3Err30Min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1Err30MinArr = np.array(top1Err30Min)\n",
    "top3Err30MinArr = np.array(top3Err30Min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func(value, tick_number):\n",
    "    tempTick = (value*30) + 30\n",
    "    ret = \"%d\"%(tempTick)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(top1Err30Min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(top1Err30MinArr))\n",
    "print(np.mean(top3Err30MinArr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
