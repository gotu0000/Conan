{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from AISDataManager import AISDataManager\n",
    "import Constants as c\n",
    "\n",
    "#config parser\n",
    "import configparser\n",
    "\n",
    "#MyConfig.INI stores all the run time constants\n",
    "config = configparser.ConfigParser()\n",
    "config.read('MyConfig.INI')\n",
    "\n",
    "#make object of AIS data manager\n",
    "aISDM = AISDataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the sorted csv for one particular vessel\n",
    "oneVesselFile = \"./Data/AIS_2017_LA/MMSI/366898250_Sorted.csv\"\n",
    "# oneVesselFile = \"./Dummy.csv\"\n",
    "oneVesselData, retVal = aISDM.load_data_from_csv(oneVesselFile)\n",
    "\n",
    "if(retVal == c.errNO['SUCCESS']):\n",
    "    print(\"Loaded Successfully\")\n",
    "    #comment if dont want to drop static features\n",
    "    dropList = ['BaseDateTime', 'VesselName', 'IMO', 'CallSign']\n",
    "    oneVesselData = aISDM.drop_columns(oneVesselData, dropList)\n",
    "    \n",
    "else:\n",
    "    print(\"Error Loading CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonMin = (float)(config['REGEION']['LON_MIN'])\n",
    "lonMax = (float)(config['REGEION']['LON_MAX'])\n",
    "\n",
    "latMin = (float)(config['REGEION']['LAT_MIN'])\n",
    "latMax = (float)(config['REGEION']['LAT_MAX'])\n",
    "\n",
    "print(lonMin,latMin)\n",
    "print(lonMax,latMax)\n",
    "\n",
    "increStep = 0.01\n",
    "incrRes = 2\n",
    "\n",
    "xGrid = np.arange(lonMin,lonMax,increStep)\n",
    "xGrid = np.around(xGrid,incrRes)\n",
    "yGrid = np.arange(latMin,latMax,increStep)\n",
    "yGrid = np.around(yGrid,incrRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retDF = aISDM.get_time_stamp_data(oneVesselData, 'DateTime', 'HourlyInterval17To18.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secDF = aISDM.append_seconds_column(retDF, 'DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(secDF.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.DataFrame({\"MMSI\":[1,2,3,4,5,6,7,8,9,10,11,12,13]\\\n",
    "                        ,\"LON\":[10,9,8,7,6,5,4,3,2,1,0,-1,-2]\\\n",
    "                        ,\"LAT\":[10,9,8,7,6,5,4,3,2,1,0,-1,-2]\\\n",
    "                        ,\"SOG\":[10,9,8,7,6,5,4,3,2,1,0,-1,-2]\\\n",
    "                        ,\"COG\":[10,9,8,7,6,5,4,3,2,1,0,-1,-2]\\\n",
    "                        ,\"Heading\":[10,9,8,7,6,5,4,3,2,1,0,-1,-2]\\\n",
    "                        ,\"Seconds\":[100,200,300,400,700,800,900,1000,1100,1200,1600,1700,1800]\\\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MMSI  LON  LAT  SOG  COG  Heading  Seconds\n",
      "0      1   10   10   10   10       10      100\n",
      "1      2    9    9    9    9        9      200\n",
      "2      3    8    8    8    8        8      300\n",
      "3      4    7    7    7    7        7      400\n",
      "4      5    6    6    6    6        6      700\n",
      "5      6    5    5    5    5        5      800\n",
      "6      7    4    4    4    4        4      900\n",
      "7      8    3    3    3    3        3     1000\n",
      "8      9    2    2    2    2        2     1100\n",
      "9     10    1    1    1    1        1     1200\n",
      "10    11    0    0    0    0        0     1600\n",
      "11    12   -1   -1   -1   -1       -1     1700\n",
      "12    13   -2   -2   -2   -2       -2     1800\n"
     ]
    }
   ],
   "source": [
    "print(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_df_for_time_series(dFObj,prevFeatureToConsider,timeStep):\n",
    "    #plus one for the prediction purpose\n",
    "    minimumRows = prevFeatureToConsider + 1\n",
    "    dFList = []\n",
    "\n",
    "    #get index of second column\n",
    "    colList = dFObj.columns.tolist() \n",
    "    colNum = colList.index('Seconds')\n",
    "    \n",
    "    prevVal = dFObj.iloc[0,colNum]\n",
    "    prevIndex = 0\n",
    "\n",
    "    for i in range(1,dFObj.shape[0]):\n",
    "        if(dFObj.iloc[i,colNum] - prevVal) > timeStep:\n",
    "            tempDF = dFObj.iloc[prevIndex:i,:].copy()\n",
    "\n",
    "            #check for minimum number of rows\n",
    "            if(tempDF.shape[0] >= minimumRows):\n",
    "                dFList.append(tempDF)\n",
    "\n",
    "            prevIndex = i\n",
    "        prevVal = dFObj.iloc[i,colNum]\n",
    "\n",
    "    tempDF = dFObj.iloc[prevIndex:dFObj.shape[0],:].copy()\n",
    "\n",
    "    if(tempDF.shape[0] >= minimumRows):\n",
    "        dFList.append(tempDF)\n",
    "    return dFList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make time series data based on previous data\n",
    "def make_time_series_data(dFObj, prevLonFeature, prevLatFeature, prevSOGFeature, prevCOGFeature\\\n",
    "                              , prevHeadingFeature, timeStep, labelColName):\n",
    "\n",
    "    #compute the maximum value\n",
    "    previousFeatures = max(prevLonFeature\\\n",
    "                            ,prevLatFeature\\\n",
    "                            ,prevSOGFeature\\\n",
    "                            ,prevCOGFeature\\\n",
    "                            ,prevHeadingFeature\\\n",
    "                          )\n",
    "    \n",
    "    print(previousFeatures)\n",
    "    \n",
    "    #offset computation\n",
    "    #useful for indexing while preparing the data\n",
    "    lonOffset = previousFeatures - prevLonFeature\n",
    "    latOffset = previousFeatures - prevLatFeature\n",
    "    sOGOffset = previousFeatures - prevSOGFeature\n",
    "    cOGOffset = previousFeatures - prevCOGFeature\n",
    "    headingOffset = previousFeatures - prevHeadingFeature\n",
    "    \n",
    "    dFSlices = slice_df_for_time_series(dFObj,previousFeatures, timeStep)\n",
    "        \n",
    "    featureMatrix = np.zeros((0,\\\n",
    "                         prevLonFeature\\\n",
    "                         +prevLatFeature\\\n",
    "                         +prevSOGFeature\\\n",
    "                         +prevCOGFeature\\\n",
    "                         +prevHeadingFeature\\\n",
    "                         ))\n",
    "    \n",
    "    print(featureMatrix.shape)\n",
    "\n",
    "    labelMatrix = np.zeros((0,1))\n",
    "    \n",
    "    #iterate through sub data frames\n",
    "    for dF in dFSlices:\n",
    "        #keep on scanning their rows\n",
    "        #its more like a sliding window\n",
    "        for rows in range(dF.shape[0]-previousFeatures):\n",
    "            sampleData = np.zeros((1,prevLonFeature\\\n",
    "                                   +prevLatFeature\\\n",
    "                                   +prevSOGFeature\\\n",
    "                                   +prevCOGFeature\\\n",
    "                                   +prevHeadingFeature\\\n",
    "                                  ))\n",
    "            sampleDataIndex = 0\n",
    "            \n",
    "            colList = dF.columns.tolist() \n",
    "            \n",
    "            colNum = colList.index('LON')\n",
    "            for ii in range(prevLonFeature):\n",
    "                sampleData[0,sampleDataIndex] = dF.iloc[rows+lonOffset+ii,colNum]\n",
    "                sampleDataIndex = sampleDataIndex + 1\n",
    "                \n",
    "            colNum = colList.index('LAT')\n",
    "            for ii in range(prevLatFeature):\n",
    "                sampleData[0,sampleDataIndex] = dF.iloc[rows+latOffset+ii,colNum]\n",
    "                sampleDataIndex = sampleDataIndex + 1\n",
    "                \n",
    "            colNum = colList.index('SOG')\n",
    "            for ii in range(prevSOGFeature):\n",
    "                sampleData[0,sampleDataIndex] = dF.iloc[rows+sOGOffset+ii,colNum]\n",
    "                sampleDataIndex = sampleDataIndex + 1\n",
    "                \n",
    "            colNum = colList.index('COG')\n",
    "            for ii in range(prevCOGFeature):\n",
    "                sampleData[0,sampleDataIndex] = dF.iloc[rows+cOGOffset+ii,colNum]\n",
    "                sampleDataIndex = sampleDataIndex + 1\n",
    "                \n",
    "            colNum = colList.index('Heading')\n",
    "            for ii in range(prevHeadingFeature):\n",
    "                sampleData[0,sampleDataIndex] = dF.iloc[rows+headingOffset+ii,colNum]\n",
    "                sampleDataIndex = sampleDataIndex + 1\n",
    "                \n",
    "            ################################\n",
    "#             print(sampleData)\n",
    "            featureMatrix = np.vstack((featureMatrix,sampleData))\n",
    "    \n",
    "            colNum = colList.index(labelColName)\n",
    "        \n",
    "            tempLabel = np.array([[dF.iloc[rows+previousFeatures,colNum]]])\n",
    "            labelMatrix = np.vstack((labelMatrix,tempLabel))\n",
    "    return featureMatrix, labelMatrix\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "(0, 8)\n",
      "[[10.  9.  8.  9.  8.  8.  8.  8.]\n",
      " [ 6.  5.  4.  5.  4.  4.  4.  4.]\n",
      " [ 5.  4.  3.  4.  3.  3.  3.  3.]\n",
      " [ 4.  3.  2.  3.  2.  2.  2.  2.]]\n",
      "[[7.]\n",
      " [3.]\n",
      " [2.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#now once we have the data\n",
    "#lets try simple prediction algorithm\n",
    "#use last LON LAT SOG COG and Heading values to predict the next values\n",
    "#simple model to predict LON values\n",
    "featureMat, labelMat = make_time_series_data(testDF, 3, 2, 1, 1, 1, 100, 'LON')\n",
    "print(featureMat)\n",
    "print(labelMat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
